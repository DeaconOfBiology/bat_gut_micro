{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bat gut microbio metagenomic analysis\n",
    "\n",
    "TJ Rogers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To do:\n",
    "  - [X] Find good host sequences so that I can remove host reads from the metagenomes.\n",
    "  - [X] Run snakemake workflow to trim reads and retrieve host reference sequences.\n",
    "  - [X] Create script to remove host reads from the fastq files.\n",
    "  - [X] Update the main `README.md` file\n",
    "  - [ ] Check the reference file to see if they all end in \"_mPhyDis1.pri.v3_genomic.fna\". If not, need to figure out how to reference them in the params section of the rule remove_host_reads in `readQC.smk`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find good host sequences so that I can remove host reads from the metagenomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have listed the sample name (host) along with the species name and the accession number for the reference seuquence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  sample                species        accession\n",
      "0  NBS1051F-30-542494038   Pteronotus parnellii  GCA_036768555.1\n",
      "1               NBS1051F   Pteronotus parnellii  GCA_036768555.1\n",
      "2  NBS1079E-30-542494038         Myotis elegans              NaN\n",
      "3  NBS1079E-30-550131958         Myotis elegans              NaN\n",
      "4            080613-8-pd  Phyllostomus discolor  GCA_004126475.3\n",
      "5           080813-19-pd  Phyllostomus discolor  GCA_004126475.3\n",
      "6            080813-7-mc       Mimon crenulatum              NaN\n",
      "7            080913-2-mc       Mimon crenulatum              NaN\n",
      "8            080913-7-ph  Phyllostomus hastatus  GCA_019186645.2\n"
     ]
    }
   ],
   "source": [
    "metadata={'sample': ['NBS1051F-30-542494038','NBS1051F','NBS1079E-30-542494038','NBS1079E-30-550131958','080613-8-pd','080813-19-pd','080813-7-mc','080913-2-mc','080913-7-ph'],\n",
    "          'species': ['Pteronotus parnellii','Pteronotus parnellii','Myotis elegans', 'Myotis elegans','Phyllostomus discolor','Phyllostomus discolor','Mimon crenulatum','Mimon crenulatum','Phyllostomus hastatus'],\n",
    "          'accession': ['GCA_036768555.1','GCA_036768555.1','NaN','NaN','GCA_004126475.3','GCA_004126475.3','NaN','NaN','GCA_019186645.2']}\n",
    "\n",
    "# Create DataFrame\n",
    "metadata = pd.DataFrame(metadata)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I already have the script written to download sequences NCBI, but the genome of some host have not been sequenced and are not found on any data base. For instance, neither Myotis elegans nor Mimon crenulatum have had their genomes sequences.\n",
    "  * However, according to Hurtado and D'Elia-2018, Mimon crenulatum is not an actual species. It is actually a clade that is composed of multiple species. One such species is M. crenulatum keenani. I found that the database 'bat1k' has the genome of M. crenulatum keenani sequenced. So I will retrieve the sequence from there. \n",
    "  * I am currently waiting on bat1k to approve my membership so I can download the sequence data I need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run snakemake workflow to trim reads and retrieve host reference sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* JobID: 11161798:\n",
    "  * Apparently this version of snakemake can not take in bash script in the arguement \"script:\". I got the following error:\n",
    "    * \"Unsupported script: Expecting either Python (.py), R (.R), RMarkdown (.Rmd) or Julia (.jl) script.\"\n",
    "\n",
    "  * I added the script path to \"params\" and changed the argument \"script\" to \"shell\". Going to try again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JobID: 11161965\n",
    "  * I made a mistake by giving the same output read file for the fr1 and fr2 slot in the in the shell section of the clean_raw_reads rule in the file readQC.smk. \n",
    "  * Made the required change and running again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JobID: 11162659\n",
    "  * For most of the samples, the adapter and phix removal worked. However, for some reason the temp fq file for sample 080913-2-mc isnt being created correctly or some other error is happening with it as snakemake is removing it and faulting out.\n",
    "  * I am troubleshooting now:\n",
    "    * Going to set up the rule to where it will create a log so I can use that to hopefully troubleshoot this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JobID: 11163418\n",
    "  * I noticed that I was having the script place the trimmed reads in the 'tmp' directory. I have changed that in the script. \n",
    "  * Once this job has stopped I need to:\n",
    "    - [x] mv the trimmed fq files to the clean_reads directory.\n",
    "  * This job failed as well for the same reason as the previous job. It said that line 23 in `trimming.sh` was not a command. Problem is I had already modified that script and was unable to figure out what line it was talking about. I am trying to run again to see what will happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JobID: 11163492\n",
    "  * Job completed without any issues as of 09-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create script to remove host reads from the fastq files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* While I am currently creating this script, it will not be able to be tested until bat1k has given me access to their data base.\n",
    "  * Script name: `host_read_removal.sh`\n",
    "  * path: `workflow/scripts/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To do:\n",
    "  - [X] Check email to see if Bat1k has granted you access to download their sequences.\n",
    "  - [X] Find missing host reference sequences or good alternatives. \n",
    "  - [X] Check status of JobID 11163492 and update on previous day's notes.\n",
    "  - [X] Read lit papers in reference to bats, bat microbiomes, and HiC ananysis.\n",
    "  - [ ] ~~Write script for assembling reads.~~\n",
    "  - [X] Make needed adjustments to the `host_read_removal.sh`.\n",
    "  - [X] Update the main `README.md` file\n",
    "  - [X] Check the reference file to see if they all end in \"_mPhyDis1.pri.v3_genomic.fna\". If not, need to figure out how to reference them in the params section of the rule remove_host_reads in `readQC.smk`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check email to see if Bat1k has granted you access to download their sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bat1k has not sent me an update as of yet. I will wait until this afternoon. If they have not gotten a hold of me by that time, I will reach out to them again.\n",
    "  * I found replacement reference sequences on NCBI and no longer need access to Bat1k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing host reference sequences or good alternatives. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Myotis elegans does not have a whole genome sequences. However, Stadelmann et al. 2007 and Moratell et al. 2013 suggest that M. elegans closest relatives are (in order of closest to least) M. simus, M. riparius, M. ruber, and M. keaysi. This gives me some options to look for. I will check the NCBI data base to see if there are seuqences for any of these to use them as a reference genome. If not, I will work my way further down the tree until i get a hit.\n",
    "  * None of the above listed options have had their genome sequenced. Howerever, I did find two genomes from members within the same clade: M. yumanesis and M. vivesi. M. vivesi is larger and eats fish as well as insects, whereas M. yumanesis seems to be more like M. elegans in size and diet. So I am going to use M. yumanesis as a stand in.\n",
    "* Mimon crenulatum (Gardnerycteris crenulatum) does not have a whole genome sequenced. However, it turns out that Phyllostomus discolor is a close relative of M. crenulatum (Hurtado et. al, 2018). So I will use it as a reference genome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below, I have updated the metatable to reflect new additions to the reference sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>species</th>\n",
       "      <th>accession</th>\n",
       "      <th>substitute_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBS1051F-30-542494038</td>\n",
       "      <td>Pteronotus parnellii</td>\n",
       "      <td>GCA_036768555.1</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBS1051F</td>\n",
       "      <td>Pteronotus parnellii</td>\n",
       "      <td>GCA_036768555.1</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBS1079E-30-542494038</td>\n",
       "      <td>Myotis elegans</td>\n",
       "      <td>GCA_028538775.1</td>\n",
       "      <td>Myotis yumanensis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBS1079E-30-550131958</td>\n",
       "      <td>Myotis elegans</td>\n",
       "      <td>GCA_028538775.1</td>\n",
       "      <td>Myotis yumanensis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>080613-8-pd</td>\n",
       "      <td>Phyllostomus discolor</td>\n",
       "      <td>GCA_004126475.3</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>080813-19-pd</td>\n",
       "      <td>Phyllostomus discolor</td>\n",
       "      <td>GCA_004126475.3</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>080813-7-mc</td>\n",
       "      <td>Mimon crenulatum</td>\n",
       "      <td>GCA_004126475.3</td>\n",
       "      <td>Phyllostomus discolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>080913-2-mc</td>\n",
       "      <td>Mimon crenulatum</td>\n",
       "      <td>GCA_004126475.3</td>\n",
       "      <td>Phyllostomus discolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>080913-7-ph</td>\n",
       "      <td>Phyllostomus hastatus</td>\n",
       "      <td>GCA_019186645.2</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sample                species        accession  \\\n",
       "0  NBS1051F-30-542494038   Pteronotus parnellii  GCA_036768555.1   \n",
       "1               NBS1051F   Pteronotus parnellii  GCA_036768555.1   \n",
       "2  NBS1079E-30-542494038         Myotis elegans  GCA_028538775.1   \n",
       "3  NBS1079E-30-550131958         Myotis elegans  GCA_028538775.1   \n",
       "4            080613-8-pd  Phyllostomus discolor  GCA_004126475.3   \n",
       "5           080813-19-pd  Phyllostomus discolor  GCA_004126475.3   \n",
       "6            080813-7-mc       Mimon crenulatum  GCA_004126475.3   \n",
       "7            080913-2-mc       Mimon crenulatum  GCA_004126475.3   \n",
       "8            080913-7-ph  Phyllostomus hastatus  GCA_019186645.2   \n",
       "\n",
       "      substitute_species  \n",
       "0                   none  \n",
       "1                   none  \n",
       "2      Myotis yumanensis  \n",
       "3      Myotis yumanensis  \n",
       "4                   none  \n",
       "5                   none  \n",
       "6  Phyllostomus discolor  \n",
       "7  Phyllostomus discolor  \n",
       "8                   none  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata2={'sample': ['NBS1051F-30-542494038','NBS1051F','NBS1079E-30-542494038','NBS1079E-30-550131958','080613-8-pd','080813-19-pd','080813-7-mc','080913-2-mc','080913-7-ph'],\n",
    "          'species': ['Pteronotus parnellii','Pteronotus parnellii','Myotis elegans', 'Myotis elegans','Phyllostomus discolor','Phyllostomus discolor','Mimon crenulatum','Mimon crenulatum','Phyllostomus hastatus'],\n",
    "          'accession': ['GCA_036768555.1','GCA_036768555.1','GCA_028538775.1','GCA_028538775.1','GCA_004126475.3','GCA_004126475.3','GCA_004126475.3','GCA_004126475.3','GCA_019186645.2'],\n",
    "          'substitute_species': ['none','none','Myotis yumanensis','Myotis yumanensis','none','none','Phyllostomus discolor','Phyllostomus discolor','none']}\n",
    "\n",
    "# Create DataFrame\n",
    "metadata2 = pd.DataFrame(metadata2)\n",
    "metadata2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check status of JobID 11163492 and update on previous day's notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Job is complete. References have been downloaded. Only issue is that I did not inlcude a command in the script to unzip the .zip file. Updating and running that portion again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JobID:11188202\n",
    "  * This job failed. Not sure what the issue was. But I have split the rule 'get_host_references' into two: 'get_host_references' and 'decompress_references'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JobID: 11188332\n",
    "  * Job complete. Now to test if the decompress_references rule works. First, I will need to unzip the ncbi file to see what the common file path is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JobID: 11189456 (Testing unzip on ncbi reference file)\n",
    "  * In this, I also added a find command to find all the '.fna' files to clean up their names\n",
    "    * IT WORKED!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JobID: 11189989\n",
    "  * I am now rerunning the get_host_references and decompress_references rules in the snakemake pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been a change of plans. I spoke to Rick today about the above pipeline. He pointed out that the lab's newest program, Titian, already does everything up to assembling the reads. It can even take in host files to use as read contamination control. The only thing it doesnt do yet is microbial binning. Rick has asked me to constuct the script to do the binning part. This gives me the oprotunity to learn more python. So, I need to do the following:\n",
    "* [X] Check over the Titian output that Josh Hensley has already produced. It is found under `/projects/raw_lab/projects/yohe_lab_bats/`.\n",
    "* [X] Find out if the contamination control part of Titain is up and running.\n",
    "* [X] Find out if Titian is making a co-assembly or if it makes individual assemblies:\n",
    "  * [X] If it makes individual assemblies, good. We can press on.\n",
    "  * [ ] ~~If it makes one co-assembly, talk to Jose about making it optional.~~\n",
    "* [ ] Write out python script to be used in Titian that bins the assembies.\n",
    "  * [ ] Find out which binners would be best to use.\n",
    "  * [ ] Build python script to bin the assemblies. Steps to include are as follows:\n",
    "    * [ ] Assemble each sample individually\n",
    "    * [ ] Bin each assembly individually using 3 different binning programs:\n",
    "      * [ ] In this step, is if it would be benifical to map all sample reads to each assembly to add in binning (Some binning programs already have this ability).\n",
    "    * [ ] Use metawrap's bin refinner to create an individual refined bin set for each sample \n",
    "    * [ ] Use Drep to depreplicate the refined bin sets so that we are left with one single bin set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To do:\n",
    "  - [X] Assemble each sample individually\n",
    "    * Titan already does seperate assemblies. This is good!\n",
    "  - [X] Write python script to bin each assembly:\n",
    "    - [ ] Bin each assembly individually using 3 different binning programs:\n",
    "        - [ ] In this step, is if it would be benifical to map all sample reads to each assembly to add in binning (Some binning programs already have this ability).\n",
    "    - [ ] Use metawrap's bin refinner to create an individual refined bin set for each sample \n",
    "    - [ ] Use Drep to depreplicate the refined bin sets so that we are left with one single bin set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Running titan\n",
    "  * JobID:11218747\n",
    "    * When this job finishes, I need to try to run my binning script on it.\n",
    "    * This job completed without issue. However, I did not deconcaminate the host DNA. This was also ran using megahit. I am currently running it again. There are 4 host sequences but Titan only takes in one fasta file at a time. So I am going to concatenate the four together and use them as one single input. Check next day for job running ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- [ ] complete script to map create read depth file for assemblers\n",
    "- [ ] complete binning functions\n",
    "- [ ] finalize peer review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Running Titan again\n",
    "  * JobID: 11226526\n",
    "    * Running Titan using both megahit and metaspades while also decontaminating\n",
    "    * For some reason this job failed. I believe it may be due to the contamination file I was using. So I am going to run again without the contamination.\n",
    "  * JobID:11226750\n",
    "* Testing mapping function for my binning script.\n",
    "  * JobID: 11242127\n",
    "    * I had to do a lot of troubleshooting, but its finally working (it looks like at least)\n",
    "    * Job failed do to not enough memory. See next day run for update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "*   Read over paper you need to review\n",
    "*   Work on binning script\n",
    "    *   Check to see Jose settings in his script for bwa\n",
    "*   Check Phasegenome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Testing mapping function for my binning script.\n",
    "  * JobID: 11271686\n",
    "    * The last job failed due to not having enough memmory so I changed the following parameter in my sbatch script:\n",
    "      * #SBATCH --mem=200gb to #SBATCH --mem=400gb\n",
    "        * if this does not work, I will follow the advice given in this link:\n",
    "          * https://stackoverflow.com/questions/52421068/error-in-slurm-cluster-detected-1-oom-kill-events-how-to-improve-running-jo\n",
    "    * Job failed. Rick just wants me to create bins and move away from the scripting. So I am moving away from this for now and am running a job to make the mags\n",
    "  * JobID: 11288072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following are in the email titled Important Biosafety training to be completed and occupational health registration\n",
    "Inbox\n",
    "  - [ ] Complete the following CBTs:\n",
    "    - [ ] Laboratory Personnel BSS\n",
    "    - [ ] Shipping and Transport of Regulated Biological Materials\n",
    "    - [ ] Animal Biosafety\n",
    "  - [ ] Complete review of the Information on Rabies Virus and Vaccination Google form\n",
    "  - [ ] Once all this required training is completed, complete the Biohazard Awareness Training \n",
    "- [X] Complete binning script\n",
    "- [ ] Complete the Active Assailant Response Training\n",
    "- [ ] Finish reviewing paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were a number of problems with the binning script:\n",
    "*   First, the error was in regards to anvio not liking \"-\" in the prefix names. So, I changed all the assembly names to have underscores. This allowed for the prefix to have underscorse as well.\n",
    "*   Next, anvio through an error because one of the assemblies started with a number. So, I added the prefix \"sample_\" to it. This solved that problem.\n",
    "*   Next, metawrap will not take gunziped files even though the programs it is using can use gunziped files. So, I modified the binning.sh script of metawrap. I changed all occurances of \"_1.fastq\" to \"_R1.fastq.gz\". This solved that problem.\n",
    "*   Finally, an older version of samtools has priority over other versions on HPC. This caused a conflict with metawrap as it uses a newer version \"1.9\". So, after trouble shooting, I made sure to load the module for samtools 1.9 in the binning script.\n",
    "\n",
    "JobID 11327447:\n",
    "*   running as of 1550\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   was only able to make a few bins from the Bat Gut data using metawrap. I am going to move on to the Green lake data and see if I can get the pipeline to work. Then I will come back here if it works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
